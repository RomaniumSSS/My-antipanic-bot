# –ü—Ä–∞–≤–∏–ª–∞ —Ä–∞–±–æ—Ç—ã —Å OpenAI API

–ü–∞—Ç—Ç–µ—Ä–Ω—ã –∏ best practices –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å OpenAI –≤ Antipanic Bot.

---

## 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞

### Async –∫–ª–∏–µ–Ω—Ç (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –¥–ª—è aiogram)

```python
from openai import AsyncOpenAI

client = AsyncOpenAI(
    api_key=config.OPENAI_KEY.get_secret_value(),
    timeout=60.0,
)
```

### –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —á–µ—Ä–µ–∑ pydantic-settings

```python
# src/config.py
from pydantic import SecretStr
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    OPENAI_KEY: SecretStr
    OPENAI_MODEL: str = "gpt-4o"
    OPENAI_TIMEOUT: float = 60.0
    OPENAI_MAX_TOKENS: int = 1000
```

---

## 2. Chat Completions

### –ë–∞–∑–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å

```python
response = await client.chat.completions.create(
    model=config.OPENAI_MODEL,
    messages=[
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": user_message},
    ],
    temperature=0.7,
    max_tokens=500,
)

result = response.choices[0].message.content
```

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å–æ–æ–±—â–µ–Ω–∏–π

```python
messages = [
    # –°–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ ‚Äî —Ä–æ–ª—å, –∫–æ–Ω—Ç–µ–∫—Å—Ç, –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
    {
        "role": "system",
        "content": """–¢—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫ –≤ Telegram-–±–æ—Ç–µ Antipanic.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø–æ–º–æ–≥–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º –ø—Ä–µ–æ–¥–æ–ª–µ–≤–∞—Ç—å –ø—Ä–æ–∫—Ä–∞—Å—Ç–∏–Ω–∞—Ü–∏—é.
–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, –ø–æ –¥–µ–ª—É, –º–∞–∫—Å–∏–º—É–º 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.
–ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å –æ—Ç–≤–µ—Ç–∞ ‚Äî —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º."""
    },
    # –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    {"role": "user", "content": "–ü—Ä–µ–¥—ã–¥—É—â–∏–π –≤–æ–ø—Ä–æ—Å"},
    {"role": "assistant", "content": "–ü—Ä–µ–¥—ã–¥—É—â–∏–π –æ—Ç–≤–µ—Ç"},
    # –¢–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å
    {"role": "user", "content": "–¢–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å"},
]
```

---

## 3. Streaming (–¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤)

### Async streaming

```python
async with client.chat.completions.stream(
    model=config.OPENAI_MODEL,
    messages=messages,
) as stream:
    full_response = ""
    async for event in stream:
        if event.type == "content.delta":
            chunk = event.delta.content or ""
            full_response += chunk
            # –ú–æ–∂–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å —á–∞–Ω–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
    
    return full_response
```

### –ü–æ–ª—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞

```python
async with client.chat.completions.stream(...) as stream:
    async for _ in stream:
        pass  # –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–æ–±—ã—Ç–∏—è

completion = await stream.get_final_completion()
result = completion.choices[0].message.content
```

---

## 4. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏

### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –±–æ—Ç–∞

```python
# –î–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —à–∞–≥–æ–≤/—Å–æ–≤–µ—Ç–æ–≤
GENERATION_PARAMS = {
    "temperature": 0.7,      # –ë–∞–ª–∞–Ω—Å –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏
    "max_tokens": 500,       # –õ–∏–º–∏—Ç –æ—Ç–≤–µ—Ç–∞
    "top_p": 0.9,            # Nucleus sampling
}

# –î–ª—è –∞–Ω–∞–ª–∏–∑–∞/–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
ANALYSIS_PARAMS = {
    "temperature": 0.3,      # –ë–æ–ª–µ–µ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ
    "max_tokens": 200,
}

# –î–ª—è –º–∏–∫—Ä–æ-—É–¥–∞—Ä–æ–≤ (–∫–æ—Ä–æ—Ç–∫–∏–µ —Å–æ–≤–µ—Ç—ã)
MICROHIT_PARAMS = {
    "temperature": 0.5,
    "max_tokens": 150,
}
```

---

## 5. –ü—Ä–æ–º–ø—Ç—ã –¥–ª—è Antipanic Bot

### –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç (–±–∞–∑–æ–≤—ã–π)

```python
SYSTEM_PROMPT = """–¢—ã ‚Äî Antipanic Bot, –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –ø—Ä–µ–æ–¥–æ–ª–µ–Ω–∏—è –ø—Ä–æ–∫—Ä–∞—Å—Ç–∏–Ω–∞—Ü–∏–∏.

–ü–†–ê–í–ò–õ–ê:
1. –û—Ç–≤–µ—á–∞–π –ö–†–ê–¢–ö–û ‚Äî –º–∞–∫—Å–∏–º—É–º 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
2. –ü—Ä–µ–¥–ª–∞–≥–∞–π –ö–û–ù–ö–†–ï–¢–ù–´–ï –¥–µ–π—Å—Ç–≤–∏—è, –Ω–µ –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–∏
3. –®–∞–≥–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤—ã–ø–æ–ª–Ω–∏–º—ã –∑–∞ 5-30 –º–∏–Ω—É—Ç
4. –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (üü¢ –ª—ë–≥–∫–∏–π, üü° —Å—Ä–µ–¥–Ω–∏–π, üî¥ —Å–ª–æ–∂–Ω—ã–π)
5. –ï—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ ‚Äî —Å–ø—Ä–æ—Å–∏, –Ω–µ –¥–æ–¥—É–º—ã–≤–∞–π

–§–û–†–ú–ê–¢ –®–ê–ì–û–í:
üü¢ [5-10 –º–∏–Ω] –ù–∞–∑–≤–∞–Ω–∏–µ —à–∞–≥–∞
üü° [15-30 –º–∏–Ω] –ù–∞–∑–≤–∞–Ω–∏–µ —à–∞–≥–∞
üî¥ [45-60 –º–∏–Ω] –ù–∞–∑–≤–∞–Ω–∏–µ —à–∞–≥–∞
"""
```

### –ü—Ä–æ–º–ø—Ç –¥–ª—è –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏–∏ —Ü–µ–ª–∏

```python
DECOMPOSE_PROMPT = """–†–∞–∑–±–µ–π —Ü–µ–ª—å –Ω–∞ 2-3 —ç—Ç–∞–ø–∞.

–¶–ï–õ–¨: {goal}
–î–ï–î–õ–ê–ô–ù: {deadline}

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
1. [–ù–∞–∑–≤–∞–Ω–∏–µ —ç—Ç–∞–ø–∞] ‚Äî –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ (—Å—Ä–æ–∫: X –¥–Ω–µ–π)
2. [–ù–∞–∑–≤–∞–Ω–∏–µ —ç—Ç–∞–ø–∞] ‚Äî –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ (—Å—Ä–æ–∫: X –¥–Ω–µ–π)
...

–≠—Ç–∞–ø—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–º–∏ –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏."""
```

### –ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —à–∞–≥–æ–≤

```python
STEPS_PROMPT = """–ü—Ä–µ–¥–ª–æ–∂–∏ 1-3 —à–∞–≥–∞ –Ω–∞ —Å–µ–≥–æ–¥–Ω—è.

–ö–û–ù–¢–ï–ö–°–¢:
- –¶–µ–ª—å: {goal}
- –¢–µ–∫—É—â–∏–π —ç—Ç–∞–ø: {stage}
- –≠–Ω–µ—Ä–≥–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {energy}/10
- –°–æ—Å—Ç–æ—è–Ω–∏–µ: {mood}

–ü–†–ê–í–ò–õ–ê:
- –ü—Ä–∏ —ç–Ω–µ—Ä–≥–∏–∏ 1-3: —Ç–æ–ª—å–∫–æ üü¢ –ª—ë–≥–∫–∏–µ —à–∞–≥–∏ (5-10 –º–∏–Ω)
- –ü—Ä–∏ —ç–Ω–µ—Ä–≥–∏–∏ 4-6: üü¢ –∏ üü° —à–∞–≥–∏
- –ü—Ä–∏ —ç–Ω–µ—Ä–≥–∏–∏ 7-10: –º–æ–∂–Ω–æ üî¥ —Å–ª–æ–∂–Ω—ã–µ —à–∞–≥–∏

–û—Ç–≤–µ—Ç—å —Å–ø–∏—Å–∫–æ–º —à–∞–≥–æ–≤."""
```

### –ü—Ä–æ–º–ø—Ç –¥–ª—è –º–∏–∫—Ä–æ-—É–¥–∞—Ä–∞

```python
MICROHIT_PROMPT = """–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞—Å—Ç—Ä—è–ª. –î–∞–π –º–∏–∫—Ä–æ-—É–¥–∞—Ä –Ω–∞ 2-5 –º–∏–Ω—É—Ç.

–ë–õ–û–ö–ï–†: {blocker_type}
–î–ï–¢–ê–õ–ò: {details}
–¢–ï–ö–£–©–ò–ô –®–ê–ì: {current_step}

–ü—Ä–µ–¥–ª–æ–∂–∏ –û–î–ù–û –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –º–∏–∫—Ä–æ-–¥–µ–π—Å—Ç–≤–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å.
–§–æ—Ä–º–∞—Ç: –∫–æ—Ä–æ—Ç–∫–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ + –ø–æ—á–µ–º—É —ç—Ç–æ –ø–æ–º–æ–∂–µ—Ç (1 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ)."""
```

---

## 6. –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –∏ retry

### Retry —Å tenacity

```python
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
)
from openai import APIError, RateLimitError, APIConnectionError

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10),
    retry=retry_if_exception_type((APIError, RateLimitError, APIConnectionError)),
)
async def make_request(messages: list) -> str:
    response = await client.chat.completions.create(
        model=config.OPENAI_MODEL,
        messages=messages,
    )
    return response.choices[0].message.content or ""
```

### Fallback –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö

```python
async def chat_with_fallback(messages: list) -> str:
    try:
        return await make_request(messages)
    except Exception as e:
        logger.error(f"OpenAI request failed: {e}")
        return "–°–µ–π—á–∞—Å –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ AI. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ."
```

---

## 7. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ AI —Å–µ—Ä–≤–∏—Å–∞

```python
# src/services/ai.py
import logging
from typing import List, Dict, Any

from openai import AsyncOpenAI
from tenacity import retry, stop_after_attempt, wait_exponential

from src.config import config

logger = logging.getLogger(__name__)


class AIService:
    def __init__(self):
        self.client = AsyncOpenAI(
            api_key=config.OPENAI_KEY.get_secret_value(),
            timeout=config.OPENAI_TIMEOUT,
        )
        self.model = config.OPENAI_MODEL

    async def _request(
        self,
        messages: List[Dict[str, Any]],
        **kwargs
    ) -> str:
        """–ë–∞–∑–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∫ API."""
        response = await self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            **kwargs
        )
        return response.choices[0].message.content or ""

    async def decompose_goal(self, goal: str, deadline: str) -> str:
        """–î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è —Ü–µ–ª–∏ –Ω–∞ —ç—Ç–∞–ø—ã."""
        messages = [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": DECOMPOSE_PROMPT.format(
                goal=goal,
                deadline=deadline
            )},
        ]
        return await self._request(messages, temperature=0.5, max_tokens=500)

    async def generate_steps(
        self,
        goal: str,
        stage: str,
        energy: int,
        mood: str
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —à–∞–≥–æ–≤ –Ω–∞ –¥–µ–Ω—å."""
        messages = [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": STEPS_PROMPT.format(
                goal=goal,
                stage=stage,
                energy=energy,
                mood=mood
            )},
        ]
        return await self._request(messages, temperature=0.7, max_tokens=400)

    async def get_microhit(
        self,
        blocker_type: str,
        details: str,
        current_step: str
    ) -> str:
        """–ú–∏–∫—Ä–æ-—É–¥–∞—Ä –ø—Ä–∏ –∑–∞—Å—Ç—Ä–µ–≤–∞–Ω–∏–∏."""
        messages = [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": MICROHIT_PROMPT.format(
                blocker_type=blocker_type,
                details=details,
                current_step=current_step
            )},
        ]
        return await self._request(messages, temperature=0.6, max_tokens=150)


# Singleton
ai_service = AIService()
```

---

## 8. –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –º–µ—Ç—Ä–∏–∫–∏

```python
import time
import logging

logger = logging.getLogger(__name__)

async def _request_with_logging(self, messages, **kwargs) -> str:
    start = time.time()
    try:
        response = await self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            **kwargs
        )
        latency = time.time() - start
        
        # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ (–±–µ–∑ PII!)
        logger.info(
            "OpenAI request",
            extra={
                "latency_ms": int(latency * 1000),
                "model": self.model,
                "prompt_tokens": response.usage.prompt_tokens,
                "completion_tokens": response.usage.completion_tokens,
            }
        )
        
        return response.choices[0].message.content or ""
    except Exception as e:
        logger.error(f"OpenAI error: {type(e).__name__}: {e}")
        raise
```

---

## 9. –ê–Ω—Ç–∏–ø–∞—Ç—Ç–µ—Ä–Ω—ã

### ‚ùå –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç

```python
# –ü–õ–û–•–û ‚Äî –±–ª–æ–∫–∏—Ä—É–µ—Ç event loop
from openai import OpenAI
client = OpenAI()

# –•–û–†–û–®–û
from openai import AsyncOpenAI
client = AsyncOpenAI()
```

### ‚ùå –•–∞—Ä–¥–∫–æ–¥ API –∫–ª—é—á–∞

```python
# –ü–õ–û–•–û
client = AsyncOpenAI(api_key="sk-...")

# –•–û–†–û–®–û
client = AsyncOpenAI(api_key=config.OPENAI_KEY.get_secret_value())
```

### ‚ùå –°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã

```python
# –ü–õ–û–•–û ‚Äî –ø—Ä–æ–º–ø—Ç –Ω–∞ 2000 —Ç–æ–∫–µ–Ω–æ–≤ —Å –ª–∏—à–Ω–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π

# –•–û–†–û–®–û ‚Äî –∫—Ä–∞—Ç–∫–∏–π, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç
```

### ‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫

```python
# –ü–õ–û–•–û
result = await client.chat.completions.create(...)

# –•–û–†–û–®–û
try:
    result = await client.chat.completions.create(...)
except RateLimitError:
    # retry –∏–ª–∏ fallback
except APIError as e:
    logger.error(f"API error: {e}")
    return FALLBACK_MESSAGE
```

---

## 10. –ß–µ–∫–ª–∏—Å—Ç

- [ ] –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è `AsyncOpenAI` –∫–ª–∏–µ–Ω—Ç
- [ ] API –∫–ª—é—á –∏–∑ `config`, –Ω–µ —Ö–∞—Ä–¥–∫–æ–¥
- [ ] –ï—Å—Ç—å retry –ª–æ–≥–∏–∫–∞ –¥–ª—è transient errors
- [ ] –ï—Å—Ç—å fallback —Å–æ–æ–±—â–µ–Ω–∏–µ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
- [ ] –ü—Ä–æ–º–ø—Ç—ã –≤—ã–Ω–µ—Å–µ–Ω—ã –≤ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã
- [ ] –õ–æ–≥–∏—Ä—É–µ—Ç—Å—è latency –∏ usage (–±–µ–∑ PII)
- [ ] temperature/max_tokens –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã –ø–æ–¥ –∑–∞–¥–∞—á—É

